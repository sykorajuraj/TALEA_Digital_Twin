"""
TALEA - Civic Digital Twin: Vulnerability Mapper
File: src/analysis/heat_stress/vulnerability_mapper.py
Author: Juraj Sýkora
Organization: Alma Mater Studiorum - Università di Bologna

Maps vulnerable populations and identifies heat islands.
"""

import pandas as pd
import geopandas as gpd
import numpy as np
from typing import Dict, List, Optional, Tuple
from scipy.ndimage import gaussian_filter


class VulnerabilityMapper:
    """Maps vulnerable populations and heat exposure"""
    
    def __init__(self):
        """Initialize vulnerability mapper"""
        pass
    
    def map_vulnerable_populations(self, 
                                   poi_gdf: gpd.GeoDataFrame,
                                   categories: Optional[List[str]] = None) -> gpd.GeoDataFrame:
        """
        Identify POIs with vulnerable populations
        
        Args:
            poi_gdf: Points of Interest GeoDataFrame
            categories: POI categories to flag as vulnerable (optional)
            
        Returns:
            GeoDataFrame with vulnerability flags
        """
        if categories is None:
            categories = [
                'healthcare', 'hospital', 'clinic', 'nursing_home',
                'school', 'kindergarten', 'education',
                'elderly', 'retirement', 'care_home'
            ]
        
        poi = poi_gdf.copy()
        
        # Check if POI has category information
        category_col = None
        for col in ['poi_category', 'category', 'type', 'amenity']:
            if col in poi.columns:
                category_col = col
                break
        
        if category_col:
            # Flag vulnerable POIs
            poi['is_vulnerable_pop'] = poi[category_col].str.lower().apply(
                lambda x: any(cat in str(x).lower() for cat in categories) 
                if pd.notna(x) else False
            )
            
            # Categorize vulnerability type
            poi['vulnerability_type'] = poi.apply(
                lambda row: self._categorize_vulnerability(
                    row[category_col] if pd.notna(row[category_col]) else ''
                ), axis=1
            )
        else:
            # No category info available
            poi['is_vulnerable_pop'] = False
            poi['vulnerability_type'] = 'unknown'
        
        vulnerable_count = poi['is_vulnerable_pop'].sum()
        print(f"  ✓ Identified {vulnerable_count} vulnerable POIs")
        
        return poi
    
    def _categorize_vulnerability(self, category: str) -> str:
        """Categorize type of vulnerable population"""
        
        category_lower = category.lower()
        
        if any(word in category_lower for word in ['school', 'kindergarten', 'education']):
            return 'children'
        elif any(word in category_lower for word in ['elderly', 'retirement', 'nursing']):
            return 'elderly'
        elif any(word in category_lower for word in ['hospital', 'clinic', 'healthcare']):
            return 'healthcare'
        else:
            return 'other'
    
    def compute_exposure_scores(self,
                               grid: gpd.GeoDataFrame,
                               heat_stress_df: pd.DataFrame,
                               temperature_col: str = 'temperature',
                               heat_index_col: str = 'heat_index') -> gpd.GeoDataFrame:
        """
        Compute heat exposure scores for grid cells
        
        Args:
            grid: Spatial grid GeoDataFrame
            heat_stress_df: DataFrame with heat stress data (must have datetime)
            temperature_col: Temperature column name
            heat_index_col: Heat index column name
            
        Returns:
            Grid with exposure scores
        """
        grid = grid.copy()
        
        if 'datetime' not in heat_stress_df.columns:
            raise ValueError("heat_stress_df must have 'datetime' column")
        
        # Calculate temporal heat metrics
        exposure_metrics = {}
        
        if temperature_col in heat_stress_df.columns:
            exposure_metrics['avg_temp'] = heat_stress_df[temperature_col].mean()
            exposure_metrics['max_temp'] = heat_stress_df[temperature_col].max()
            exposure_metrics['hot_days'] = (heat_stress_df[temperature_col] >= 30).sum()
        
        if heat_index_col in heat_stress_df.columns:
            exposure_metrics['avg_heat_index'] = heat_stress_df[heat_index_col].mean()
            exposure_metrics['max_heat_index'] = heat_stress_df[heat_index_col].max()
        
        # Days with extreme heat
        if 'heat_index_level' in heat_stress_df.columns:
            extreme_days = heat_stress_df['heat_index_level'].isin(
                ['danger', 'extreme_danger']
            ).sum()
            exposure_metrics['extreme_heat_days'] = extreme_days
        
        # Add uniform exposure metrics to all grid cells
        for metric, value in exposure_metrics.items():
            grid[metric] = value
        
        # Compute composite exposure score
        if 'avg_heat_index' in grid.columns and 'extreme_heat_days' in grid.columns:
            # Normalize components
            hi_norm = (grid['avg_heat_index'] - grid['avg_heat_index'].min()) / \
                     (grid['avg_heat_index'].max() - grid['avg_heat_index'].min() + 1e-10)
            
            extreme_norm = (grid['extreme_heat_days'] - grid['extreme_heat_days'].min()) / \
                          (grid['extreme_heat_days'].max() - grid['extreme_heat_days'].min() + 1e-10)
            
            # Weighted composite score
            grid['exposure_score'] = 0.6 * hi_norm + 0.4 * extreme_norm
        
        print(f"  ✓ Computed exposure scores for {len(grid)} grid cells")
        
        return grid
    
    def identify_heat_islands(self,
                             grid: gpd.GeoDataFrame,
                             temperature_df: pd.DataFrame,
                             temperature_col: str = 'temperature',
                             threshold_percentile: float = 75.0,
                             smooth_sigma: float = 1.0) -> gpd.GeoDataFrame:
        """
        Identify urban heat islands
        
        Args:
            grid: Spatial grid GeoDataFrame
            temperature_df: Temperature data with spatial grid_id
            temperature_col: Temperature column name
            threshold_percentile: Percentile for heat island threshold
            smooth_sigma: Gaussian smoothing sigma (for spatial continuity)
            
        Returns:
            Grid with heat island flags
        """
        grid = grid.copy()
        
        # Aggregate temperature by grid cell
        if 'grid_id' in temperature_df.columns:
            temp_by_grid = temperature_df.groupby('grid_id')[temperature_col].agg([
                'mean', 'max', 'std'
            ]).reset_index()
            temp_by_grid.columns = ['grid_id', 'avg_temp', 'max_temp', 'temp_std']
            
            grid = grid.merge(temp_by_grid, on='grid_id', how='left')
        elif temperature_col in temperature_df.columns:
            # If no spatial info, use temporal statistics
            avg_temp = temperature_df[temperature_col].mean()
            max_temp = temperature_df[temperature_col].max()
            grid['avg_temp'] = avg_temp
            grid['max_temp'] = max_temp
        else:
            raise ValueError(f"Cannot find temperature data")
        
        # Fill missing values
        grid['avg_temp'] = grid['avg_temp'].fillna(grid['avg_temp'].mean())
        
        # Identify heat islands (top percentile)
        threshold = grid['avg_temp'].quantile(threshold_percentile / 100)
        grid['is_heat_island'] = grid['avg_temp'] >= threshold
        
        # Intensity classification
        temps = grid['avg_temp']

        if temps.nunique() == 1:
        # All grid cells have the same temperature
            grid['heat_island_intensity'] = 'moderate'
        else:
            grid['heat_island_intensity'] = pd.cut(
                temps,
                bins=[
                    temps.min(),
                    temps.quantile(0.50),
                    temps.quantile(0.75),
                    temps.quantile(0.90),
                    temps.max()
                ],
                labels=['low', 'moderate', 'high', 'extreme'],
                include_lowest=True,
                duplicates='drop'
            )
        
        heat_island_count = grid['is_heat_island'].sum()
        print(f"  ✓ Identified {heat_island_count} heat island cells "
              f"(>{threshold:.1f}°C)")
        
        return grid
    
    def compute_vulnerability_index(self,
                                   grid: gpd.GeoDataFrame,
                                   poi_gdf: Optional[gpd.GeoDataFrame] = None) -> gpd.GeoDataFrame:
        """
        Compute composite vulnerability index
        
        Combines:
        - Heat exposure
        - Vulnerable population density
        - Heat island intensity
        
        Args:
            grid: Grid with exposure scores and heat island flags
            poi_gdf: POI data with vulnerability flags (optional)
            
        Returns:
            Grid with vulnerability index
        """
        grid = grid.copy()
        
        # Count vulnerable POIs per grid cell
        if poi_gdf is not None and 'is_vulnerable_pop' in poi_gdf.columns:
            vulnerable_poi = poi_gdf[poi_gdf['is_vulnerable_pop']]
            
            # Spatial join
            poi_in_grid = gpd.sjoin(
                vulnerable_poi, 
                grid[['grid_id', 'geometry']], 
                how='inner', 
                predicate='within'
            )
            
            vuln_counts = poi_in_grid.groupby('grid_id').size().reset_index(
                name='vulnerable_poi_count'
            )
            
            grid = grid.merge(vuln_counts, on='grid_id', how='left')
            grid['vulnerable_poi_count'] = grid['vulnerable_poi_count'].fillna(0)
            
            # Density
            if 'area_km2' in grid.columns:
                grid['vulnerable_poi_density'] = grid['vulnerable_poi_count'] / grid['area_km2']
        else:
            grid['vulnerable_poi_count'] = 0
            grid['vulnerable_poi_density'] = 0
        
        # Normalize components
        components = {}
        
        if 'exposure_score' in grid.columns:
            components['exposure'] = grid['exposure_score']
        elif 'avg_temp' in grid.columns:
            components['exposure'] = self._normalize(grid['avg_temp'])
        
        if 'vulnerable_poi_density' in grid.columns:
            components['population'] = self._normalize(grid['vulnerable_poi_density'])
        
        if 'is_heat_island' in grid.columns:
            components['heat_island'] = grid['is_heat_island'].astype(float)
        
        # Compute weighted vulnerability index
        if components:
            weights = {
                'exposure': 0.4,
                'population': 0.4,
                'heat_island': 0.2
            }
            
            grid['vulnerability_index'] = sum(
                components.get(key, 0) * weight 
                for key, weight in weights.items() 
                if key in components
            )
            
            # Normalize to 0-1
            grid['vulnerability_index'] = self._normalize(grid['vulnerability_index'])
            
            # Classification
            grid['vulnerability_class'] = pd.cut(
                grid['vulnerability_index'],
                bins=[0, 0.25, 0.50, 0.75, 1.0],
                labels=['low', 'moderate', 'high', 'critical'],
                include_lowest=True
            )
        
        print(f"  ✓ Computed vulnerability index")
        
        return grid
    
    @staticmethod
    def _normalize(series: pd.Series) -> pd.Series:
        """Normalize series to 0-1 range"""
        min_val = series.min()
        max_val = series.max()
        
        if max_val - min_val == 0:
            return pd.Series(0.5, index=series.index)
        
        return (series - min_val) / (max_val - min_val)
    
    def generate_vulnerability_report(self,
                                     grid: gpd.GeoDataFrame,
                                     poi_gdf: Optional[gpd.GeoDataFrame] = None) -> Dict:
        """
        Generate comprehensive vulnerability report
        
        Args:
            grid: Grid with vulnerability analysis
            poi_gdf: POI data (optional)
            
        Returns:
            Dictionary with report statistics
        """
        report = {}
        
        # Heat island statistics
        if 'is_heat_island' in grid.columns:
            heat_islands = grid['is_heat_island'].sum()
            heat_island_pct = (heat_islands / len(grid)) * 100
            
            report['heat_islands'] = {
                'count': int(heat_islands),
                'percentage': float(heat_island_pct),
                'total_cells': len(grid)
            }
        
        # Vulnerability statistics
        if 'vulnerability_index' in grid.columns:
            report['vulnerability'] = {
                'mean_index': float(grid['vulnerability_index'].mean()),
                'max_index': float(grid['vulnerability_index'].max()),
                'critical_cells': int((grid['vulnerability_index'] >= 0.75).sum())
            }
        
        if 'vulnerability_class' in grid.columns:
            class_dist = grid['vulnerability_class'].value_counts()
            report['vulnerability_distribution'] = {
                str(k): int(v) for k, v in class_dist.items()
            }
        
        # Vulnerable population
        if poi_gdf is not None and 'is_vulnerable_pop' in poi_gdf.columns:
            vuln_poi = poi_gdf['is_vulnerable_pop'].sum()
            
            report['vulnerable_populations'] = {
                'total_vulnerable_poi': int(vuln_poi),
                'total_poi': len(poi_gdf),
                'percentage': float((vuln_poi / len(poi_gdf)) * 100)
            }
            
            if 'vulnerability_type' in poi_gdf.columns:
                type_dist = poi_gdf[poi_gdf['is_vulnerable_pop']]['vulnerability_type'].value_counts()
                report['vulnerable_populations']['by_type'] = {
                    str(k): int(v) for k, v in type_dist.items()
                }
        
        # Exposure statistics
        if 'exposure_score' in grid.columns:
            report['exposure'] = {
                'mean_score': float(grid['exposure_score'].mean()),
                'max_score': float(grid['exposure_score'].max()),
                'high_exposure_cells': int((grid['exposure_score'] >= 0.75).sum())
            }
        
        return report